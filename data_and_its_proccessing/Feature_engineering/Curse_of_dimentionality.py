"""
features->dimensions
    ->there is an optimal number of features where the increase in the number of features
      it won't increase the accuracy ,it might in return decrease the accuracy
    ->examples: Images , Text data
    ->Sparsity, in the context of data structures and matrices, refers to the condition where a large 
      proportion of the elements are zero or insignificant   
      Weight of the valuable samples reduces.
"""

"""
For this we use dimentionality reduction->
Feature selection->
    Forward selection:
    Backward elimination:
Feature Extraction->
    PCA
    LDA
    T-su
"""
